{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c1357c4-5570-4347-bc0f-065b1f229c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 10:58:17.960883: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-08 10:58:18.170089: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-08 10:58:18.209468: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-02-08 10:58:18.209491: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-02-08 10:58:18.876503: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-02-08 10:58:18.876609: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-02-08 10:58:18.876612: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "from os.path import join\n",
    "import json\n",
    "from selfpeptide.utils.constants import MIN_PEPTIDE_LEN, MAX_PEPTIDE_LEN\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed5c0516-2a11-412e-bc71-610b7b71954c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accumulate_batches': 1,\n",
       " 'batch_size': 64,\n",
       " 'cool_down': 0.8,\n",
       " 'data_folder': '/home/gvisona/SelfPeptides',\n",
       " 'early_stopping': False,\n",
       " 'experiment_group': 'FinetuneESM2',\n",
       " 'experiment_name': 'ESM_sweep_3_cont',\n",
       " 'force_restart': False,\n",
       " 'lr': 3.69224483345e-07,\n",
       " 'max_updates': 100000,\n",
       " 'min_frac': 0.1,\n",
       " 'mlm_fraction': 0.15,\n",
       " 'momentum': 0.99,\n",
       " 'nesterov_momentum': True,\n",
       " 'patience': 10000,\n",
       " 'peptides_dataframes': ['processed_data/Immunogenicity/Processed_TCell_IEDB_beta_summed.csv',\n",
       "  'processed_data/Immunogenicity/DHLAP_immunogenicity_data.csv',\n",
       "  'processed_data/Binding_Affinity/DHLAP_binding_affinity_data.csv',\n",
       "  'processed_data/Binding_Affinity/HLA_Ligand_Atlas_processed.csv'],\n",
       " 'pretrained_model': 'facebook/esm2_t12_35M_UR50D',\n",
       " 'project_folder': '/fast/gvisona/SelfPeptides',\n",
       " 'ramp_up': 0.1,\n",
       " 'resume_checkpoint_path': '/lustre/fast/fast/gvisona/SelfPeptides/outputs/FinetuneESM2/ESM_sweep_3/proud-sweep-12/checkpoints/001_checkpoint.pt',\n",
       " 'seed': 23217,\n",
       " 'seed2': 93256,\n",
       " 'test_run': False,\n",
       " 'test_size': 0.15,\n",
       " 'val_size': 0.1,\n",
       " 'validate_every_n_updates': 10,\n",
       " 'wandb_sweep': True,\n",
       " 'weight_decay': 1e-05,\n",
       " 'run_number': 23217}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../trained_models/PeptideESM/config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54041f1d-93cd-44bf-acf2-f61bcca9079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PeptidesDataset(Dataset):\n",
    "    def __init__(self, peptides):\n",
    "        super().__init__()\n",
    "        self.peptides = peptides\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.peptides)\n",
    "    \n",
    "    def __getitem__(self, ix):\n",
    "        return self.peptides[ix]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "162144cc-41d7-41f6-b9bf-05c1b7af7c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [\n",
    "        \"processed_data/Immunogenicity/Processed_TCell_IEDB_beta_summed.csv\",\n",
    "        \"processed_data/Immunogenicity/DHLAP_immunogenicity_data.csv\",\n",
    "        # \"processed_data/Binding_Affinity/DHLAP_binding_affinity_data.csv\",\n",
    "        # \"processed_data/Binding_Affinity/HLA_Ligand_Atlas_processed.csv\"        \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "645ee15b-cfd8-4a81-8291-fc59cdf7dd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of peptides: 18653\n",
      "Total number of peptides: 17784\n"
     ]
    }
   ],
   "source": [
    "peptides_set = set()\n",
    "for dname in dataframes:\n",
    "    dpath = join(\"..\", dname)\n",
    "    df = pd.read_csv(dpath)\n",
    "    peptides_set.update(df[\"Peptide\"].values)\n",
    "n_peptides = len(peptides_set)\n",
    "peptides_set = sorted(list(peptides_set))\n",
    "peptides_set = [p for p in peptides_set if len(p)>=MIN_PEPTIDE_LEN and len(p)<=MAX_PEPTIDE_LEN]\n",
    "n_peptides = len(peptides_set)\n",
    "print(f\"Total number of peptides: {n_peptides}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9959afc0-b164-4d7a-9d5f-e1eb19cf824e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EsmForMaskedLM(\n",
       "  (esm): EsmModel(\n",
       "    (embeddings): EsmEmbeddings(\n",
       "      (word_embeddings): Embedding(33, 480, padding_idx=1)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (position_embeddings): Embedding(1026, 480, padding_idx=1)\n",
       "    )\n",
       "    (encoder): EsmEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (key): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (value): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (emb_layer_norm_after): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (contact_head): EsmContactPredictionHead(\n",
       "      (regression): Linear(in_features=240, out_features=1, bias=True)\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (lm_head): EsmLMHead(\n",
       "    (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "    (layer_norm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=480, out_features=33, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "tokenizer = AutoTokenizer.from_pretrained(config[\"pretrained_model\"])\n",
    "model = AutoModelForMaskedLM.from_pretrained(config[\"pretrained_model\"])\n",
    "# model.to(device)\n",
    "checkpoint = torch.load(\"../trained_models/PeptideESM/checkpoints/001_checkpoint.pt\", map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0fdf1938-a688-4965-8ec2-c53996573c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peptides = sorted(list(peptides_set))\n",
    "dset = PeptidesDataset(peptides)\n",
    "loader = DataLoader(dset, batch_size=config[\"batch_size\"], drop_last=False)\n",
    "len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cc8a729f-a8dd-456e-a7e9-207f8b66c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2peptide = {i: p for i, p in enumerate(peptides)}\n",
    "peptide2idx = {v: k for k, v in idx2peptide.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "627da015-c430-49b5-b7f7-d1b66e59a41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b60f7400f841b384ce45f2ccd54756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.32482213, -0.261438  ,  0.06593953, ..., -0.17181304,\n",
       "        -0.02496444,  0.06054433],\n",
       "       [ 0.22507007, -0.32995966,  0.0617824 , ..., -0.09029019,\n",
       "        -0.06718121, -0.04255965],\n",
       "       [ 0.257103  , -0.256661  ,  0.08057274, ..., -0.03303841,\n",
       "        -0.05134671,  0.03509901],\n",
       "       ...,\n",
       "       [ 0.11365138, -0.0996558 ,  0.1326552 , ...,  0.00160837,\n",
       "        -0.0227115 ,  0.26673147],\n",
       "       [-0.04526203, -0.04576126,  0.15663567, ..., -0.07438464,\n",
       "         0.08082509,  0.20639467],\n",
       "       [ 0.07167291,  0.03618845,  0.06238944, ...,  0.02734216,\n",
       "         0.12952381,  0.31710804]], dtype=float32)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peptide_embeddings = []\n",
    "model.eval()\n",
    "for ix, batch in tqdm(enumerate(loader)):\n",
    "    encoded_batch = tokenizer(batch, return_tensors=\"pt\", padding=True)#.to(device)\n",
    "    # masked_batch = mask_tokenized_inputs(encoded_batch, mlm_fraction=config[\"mlm_fraction\"], mask_token_id=tokenizer.mask_token_id).to(device)\n",
    "    # labels = torch.where(masked_batch.input_ids == tokenizer.mask_token_id, encoded_batch[\"input_ids\"].to(device), -100)\n",
    "    outputs = model(**encoded_batch, output_hidden_states=True)\n",
    "    \n",
    "    for j in range(len(batch)):\n",
    "        a_mask = encoded_batch[\"attention_mask\"][j]\n",
    "        \n",
    "        sample_embedding = outputs[\"hidden_states\"][-1][j] #torch.mean(, dim=1)\n",
    "        p_embedding = torch.mean(sample_embedding[a_mask.bool()][1:-1], dim=0) # remove special tokens\n",
    "        peptide_embeddings.append(p_embedding.detach().numpy())\n",
    "peptide_embeddings = np.vstack(peptide_embeddings)\n",
    "peptide_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "59e14905-85b7-4a6c-9707-a9556a5fb0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17784, 480)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peptide_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cf891199-58ed-4135-95d0-411b5f7b45c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<cls> A A A A A I F V I <eos> <pad> <pad> <pad>'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoded_batch['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "19d10aee-9b72-4798-bc1c-6c8ddabe09fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../processed_data/Peptide_embeddings/FinetunedESM2_imm_peptides_embeddings.npy\", peptide_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d5697623-2143-492a-ad82-880c7ce3e9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../processed_data/Peptide_embeddings/ESM2_idx2peptide.json\", \"w\") as f:\n",
    "    json.dump(idx2peptide, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12886fda-cd8b-4bf1-9193-2b10c39a0640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
