{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "207daa77-6316-4893-9cc9-c7bea6046a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9957f0d3-28b9-4fe4-970b-60f31e1114e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]],\n",
       "\n",
       "        [[12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.],\n",
       "         [20., 21., 22., 23.]]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_embs = torch.tensor(np.arange(2*3*4).reshape(2,3,4)).float()\n",
    "seq_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "dc9dd6ae-7717-4519-a2b0-6ae1e1e6c341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 1],\n",
       "        [1, 1, 0]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_mask = torch.tensor([[1, 0, 1], [1, 1, 0]])\n",
    "padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5b694df1-a684-4bac-88bb-a59875c1b377",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAB_MaskedAttention(nn.Module):\n",
    "    def __init__(self, dim_Q, dim_K, dim_V, num_heads, ln=False):\n",
    "        super(MAB_MaskedAttention, self).__init__()\n",
    "        self.dim_V = dim_V\n",
    "        self.num_heads = num_heads\n",
    "        self.fc_q = nn.Linear(dim_Q, dim_V)\n",
    "        self.fc_k = nn.Linear(dim_K, dim_V)\n",
    "        self.fc_v = nn.Linear(dim_K, dim_V)\n",
    "        if ln:\n",
    "            self.ln0 = nn.LayerNorm(dim_V)\n",
    "            self.ln1 = nn.LayerNorm(dim_V)\n",
    "        self.fc_o = nn.Linear(dim_V, dim_V)\n",
    "        \n",
    "        self.mask_val=1.0e10 \n",
    "\n",
    "    def forward(self, Q, K, padding_mask=None):\n",
    "        Q = self.fc_q(Q)\n",
    "        K, V = self.fc_k(K), self.fc_v(K)\n",
    "\n",
    "        dim_split = self.dim_V // self.num_heads\n",
    "        Q_ = torch.cat(Q.split(dim_split, 2), 0)\n",
    "        K_ = torch.cat(K.split(dim_split, 2), 0)\n",
    "        V_ = torch.cat(V.split(dim_split, 2), 0)\n",
    "\n",
    "        if padding_mask is not None:\n",
    "            M = padding_mask.repeat(self.num_heads, 1).unsqueeze(1)\n",
    "            A = torch.softmax((Q_.bmm(K_.transpose(1,2)) - self.mask_val * (1-M))/math.sqrt(self.dim_V), 2)\n",
    "        else:\n",
    "            A = torch.softmax(Q_.bmm(K_.transpose(1,2))/math.sqrt(self.dim_V), 2)\n",
    "        O = torch.cat((Q_ + A.bmm(V_)).split(Q.size(0), 0), 2)\n",
    "        O = O if getattr(self, 'ln0', None) is None else self.ln0(O)\n",
    "        O = O + F.relu(self.fc_o(O))\n",
    "        O = O if getattr(self, 'ln1', None) is None else self.ln1(O)\n",
    "        return O\n",
    "    \n",
    "\n",
    "class PMA_MaskedAttention(nn.Module):\n",
    "    def __init__(self, dim, num_heads, num_seeds, ln=False):\n",
    "        super(PMA_MaskedAttention, self).__init__()\n",
    "        self.S = nn.Parameter(torch.Tensor(1, num_seeds, dim))\n",
    "        nn.init.xavier_uniform_(self.S)\n",
    "        self.mab = MAB_MaskedAttention(dim, dim, dim, num_heads, ln=ln)\n",
    "\n",
    "    def forward(self, X, padding_mask=None):\n",
    "        return self.mab(self.S.repeat(X.size(0), 1, 1), X, padding_mask=padding_mask).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3013a8c4-01ca-4cd1-a7da-f20843f93fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpma = PMA_MaskedAttention(4, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "6f41ecb9-2705-48bf-b6b4-4105a814e145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.6991,  2.4427,  3.0977,  0.8994],\n",
       "        [16.5145,  5.2091,  6.7333, -1.4213]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpma(seq_embs, padding_mask=padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e6bce427-fafd-4121-bedf-326ae4fd551f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.5866,  2.0569,  2.5016,  0.9922],\n",
       "        [19.2559,  6.1450,  7.7827, -1.8514]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpma(seq_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "757173fe-f8e7-4e6e-83c3-7527bd1b0cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 1],\n",
       "        [1, 1, 0]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "df6176fb-c70d-496d-9eed-a9f962ab6513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]],\n",
       "\n",
       "        [[12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.],\n",
       "         [20., 21., 22., 23.]]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_embs = torch.tensor(np.arange(2*3*4).reshape(2,3,4)).float()\n",
    "seq_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f1c5305e-8923-42ac-87d9-02c5e9febab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.2991,  3.4109,  1.0523,  7.3991],\n",
       "        [18.8012, 11.3980,  1.0347, 28.8672]], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpma(seq_embs, padding_mask=padding_mask).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6326d095-a66d-4694-b30e-2eeed3c13dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.0328,  2.0207,  1.0524,  7.3961],\n",
       "        [14.1593,  8.0110,  1.0391, 23.4972]], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpma(seq_embs).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5693ad41-5416-4442-99c7-d98a48c14084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.,  3.],\n",
       "         [ 0.,  0.,  0.,  0.],\n",
       "         [ 8.,  9., 10., 11.]],\n",
       "\n",
       "        [[12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.],\n",
       "         [20., 21., 22., 23.]]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_embs2 = seq_embs.clone()\n",
    "seq_embs2[0,1] = 0\n",
    "seq_embs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "32ff9034-2979-4fef-bbc6-48a3cce4f9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.6991,  2.4427,  3.0977,  0.8994],\n",
       "        [16.5145,  5.2091,  6.7333, -1.4213]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpma(seq_embs, padding_mask=padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a24c35fd-96c8-494c-a10f-25683807063d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.6991,  2.4427,  3.0977,  0.8994],\n",
       "        [16.5145,  5.2091,  6.7333, -1.4213]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpma(seq_embs2, padding_mask=padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c9b8a4c0-a516-48d3-b49a-a5a4c0bea2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.5866,  2.0569,  2.5016,  0.9922],\n",
       "        [19.2559,  6.1450,  7.7827, -1.8514]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpma(seq_embs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "cc4d410e-18a4-4df2-bf79-4e924b9bbb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.1887,  2.2432,  2.9295,  0.8819],\n",
       "        [19.2559,  6.1450,  7.7827, -1.8514]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpma(seq_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "107d56d3-fd88-4ca2-b08e-7ee9518f3f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]],\n",
       "\n",
       "        [[12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.],\n",
       "         [20., 21., 22., 23.]]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7084e56-fbec-4e8d-894f-d58912d20ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
