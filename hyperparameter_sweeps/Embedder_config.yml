method: random
metric:
  goal: minimize
  name: train/loss
parameters:
  embedding_dim:
    value: 512
  projection_hidden_dim:
    value: 2048
  projection_dim:
    value: 32
  PMA_num_heads:
    value: 1
  PMA_ln:
    value: True
  num_heads:
    value: 1
  transf_hidden_dim:
    value: 2048
  n_attention_layers:
    value: 2
  accumulate_batches:
    value: 1
  batch_size:
    value: 32
  cool_down:
    value: 0.6
  experiment_group:
    value: SP_Embedder
  experiment_name:
    value: Embeddings_CMT_allPairs_overfit
  lr:
    distribution: log_uniform_values 
    max: 5.0e-3
    min: 1e-7
  momentum:
    values: 
    - 0.9
    - 0.99
  nesterov_momentum:
    values: 
    - True
    - False
  max_updates:
    value: 100000
  min_frac:
    value: 0.1
  dropout_p:
    value: 0.0 
  project_folder:
    value: /fast/gvisona/SelfPeptides
  ramp_up:
    value: 0.3
  seed:
    value: 0
  val_size:
    value: 10
  ref_size:
    value: 10
  gen_size:
    value: 1000
  validate_every_n_updates:
    value: 16
  weight_decay:
    value: 0.0
  early_stopping:
    value: False
  patience:
    value: 1000
  hdf5_dataset:
    value: "/home/gvisona/SelfPeptides/processed_data/Self_nonSelf/pre_tokenized_peptides_dataset.hdf5"
  test_run:
    value: True
  reg_weight:
    value: 1e-4
  margin:
    value: 0.8