method: random
metric:
  goal: minimize
  name: train/loss
parameters:
  embedding_dim:
    value: 512
  PMA_num_heads:
    value: 1
  PMA_ln:
    value: True
  num_heads:
    value: 4
  transf_hidden_dim:
    value: 1024
  n_attention_layers:
    value: 2
  accumulate_batches:
    values: 
    - 16
    - 64
    - 256
    - 1024
  batch_size:
    values: 
    - 16
    - 64
  cool_down:
    value: 0.8
  experiment_group:
    value: SP_Embedder
  experiment_name:
    value: Embeddings_hinge_onlytrain
  lr:
    distribution: log_uniform_values 
    max: 5.0e-1
    min: 1e-6
  momentum:
    values: 
    - 0.9
    - 0.99
  nesterov_momentum:
    value: True
  max_updates:
    value: 100000
  min_frac:
    value: 0.1
  dropout_p:
    value: 0.0 
  project_folder:
    value: /fast/gvisona/SelfPeptides
  ramp_up:
    value: 0.1
  seed:
    value: 0
  val_size:
    value: 5000
  ref_size:
    value: 10000
  gen_size:
    value: 1000000
  validate_every_n_updates:
    value: 500
  weight_decay:
    values: 
    - 0.0
    - 0.00001
  early_stopping:
    value: False
  patience:
    value: 1000
  hdf5_dataset:
    value: "/home/gvisona/SelfPeptides/processed_data/pre_tokenized_peptides_dataset.hdf5"
  test_run:
    value: False
  reg_weight:
    value: 1e-4
  margin:
    value: 0.8