method: grid
metric:
  goal: minimize
  name: train/loss
parameters:
  embedding_dim:
    value: 512
  projection_hidden_dim:
    value: 2048
  projection_dim:
    value: 32
  PMA_num_heads:
    value: 1
  PMA_ln:
    value: True
  num_heads:
    value: 4
  transf_hidden_dim:
    value: 2048
  n_attention_layers:
    value: 2
  accumulate_batches:
    value: 1
  batch_size:
    value: 32
  cool_down:
    value: 0.6
  experiment_group:
    value: SP_Embedder
  experiment_name:
    value: Embeddings_CMT_lr_sweep
  lr:
    values:
    - 1.0e-3
    - 3.0e-4
    - 1.0e-4
    - 3.3e-5
    - 1.0e-5
  momentum:
    values: 
    - 0.9
    - 0.99
  nesterov_momentum:
    value: True
  max_updates:
    value: 10000000
  min_frac:
    value: 0.1
  dropout_p:
    value: 0.0
  project_folder:
    value: /fast/gvisona/SelfPeptides
  ramp_up:
    value: 0.1
  seed:
    value: 100001
  val_size:
    value: 5000
  test_size:
    value: 5000
  ref_size:
    value: 10000
  validate_every_n_updates:
    value: 50000
  weight_decay:
    value: 0.000001
  early_stopping:
    value: True
  test_run:
    value: False
  patience:
    value: 1000
  hdf5_dataset:
    value: "/home/gvisona/SelfPeptides/processed_data/Self_nonSelf/pre_tokenized_peptides_dataset.hdf5"
  reg_weight:
    value: 1e-4
  margin:
    value: 0.6
  loss_s:
    value: 10.0
  pretrained_aa_embeddings:
    value: "/home/gvisona/SelfPeptides/processed_data/aa_embeddings/learned_BA_AA_embeddings.npy"